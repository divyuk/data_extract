1. Comparing the Python Comparison Operators
    1. <a href="https://realpython.com/python-is-identity-vs-equality/
">python-is-identity-vs-equality</a>
2. reset_index pandas dataframe
    1. <a href="https://www.machinelearningplus.com/pandas/pandas-reset-index/
">pandas-reset-index</a>
3. parsing netsted dictionary
    1. <a href="https://towardsdatascience.com/how-do-i-extract-nested-data-in-python-4e7bed37566a. Good
">LINK</a>
4. Python Code optimisation
    1. <a href="https://hackernoon.com/python-code-optimization-tips-for-developers-6vjjw3zjq
">python-code-optimization-tips-for-developers-6vjjw3zjq</a>
    2. <a href="https://www.techbeamers.com/python-code-optimization-tips-tricks/
">python-code-optimization-tips-tricks</a>
5. deployment in AWS
    1. <a href="https://www.youtube.com/watch?v=oOqqwYI60FI
">LINK</a>
    2. <a href="https://www.youtube.com/watch?v=6cg5ERPQ2v8
">LINK</a>
    3. <a href="https://www.youtube.com/watch?v=KFuc2KWrTHs
">LINK</a>
6. How to create fully automated ML workflows with Amazon SageMaker Pipelines
    1. <a href="https://www.youtube.com/watch?v=W7uabCTfLrg
">LINK</a>
7. Call an Amazon SageMaker model endpoint using Amazon API Gateway and AWS Lambda
    1. <a href="https://www.youtube.com/watch?v=i6FcFZyy2N0&t=403s
">LINK</a>
8. text summarization
    1. <a href="https://www.machinecurve.com/index.php/2020/12/21/easy-text-summarization-with-huggingface-transformers-and-machine-learning/
">easy-text-summarization-with-huggingface-transformers-and-machine-learning</a>
    2. <a href="https://towardsdatascience.com/setting-up-a-text-summarisation-project-introduction-526622eea4a8
">setting-up-a-text-summarisation-project-introduction-526622eea4a8</a>
    3. <a href="https://towardsdatascience.com/entity-level-factual-consistency-in-abstractive-text-summarization-cb19e8a48397
">entity-level-factual-consistency-in-abstractive-text-summarization-cb19e8a48397</a>
9. text summarization using BART
    1. <a href="https://www.youtube.com/watch?v=8F0Lx53XO3w
">LINK</a>
    2. <a href="https://www.youtube.com/watch?v=fgmA9am9qCo
">LINK</a>
10. Keras
    1. <a href="https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/
">how-to-load-convert-and-save-images-with-the-keras-api</a>
11. Image captioning
    1. <a href="https://medium.com/swlh/automatic-image-captioning-using-deep-learning-5e899c127387
">automatic-image-captioning-using-deep-learning-5e899c127387</a>
    2. <a href="https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/
">develop-a-deep-learning-caption-generation-model-in-python</a>
    3. <a href="https://medium.com/swlh/image-captioning-using-attention-mechanism-f3d7fc96eb0e
">image-captioning-using-attention-mechanism-f3d7fc96eb0e</a>
12. Ecommerce products caption and image crawled
13. Blue Score
    1. <a href="https://towardsdatascience.com/bleu-bilingual-evaluation-understudy-2b4eab9bcfd1
">bleu-bilingual-evaluation-understudy-2b4eab9bcfd1</a>
    2. <a href="https://machinelearningmastery.com/calculate-bleu-score-for-text-python/
">calculate-bleu-score-for-text-python</a>
14. Greedy and beam Search
    1. <a href="https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24
">foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24</a>
15. Creating text encoding features NLP countvectorizer tfidfvectorizer
    1. <a href="https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/
">prepare-text-data-machine-learning-scikit-learn</a>
16. Word Embedding techniques
    1. <a href="https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html
">guide-word-embedding-techniques-nlp</a>
17. https kavita ganesan com how to use countvectorizer YglEgDYzb6B
    1. <a href="https://machinelearningmastery.com/develop-word-embeddings-python-gensim/
">develop-word-embeddings-python-gensim</a>
    2. <a href="https://machinelearningmastery.com/what-are-word-embeddings/
">what-are-word-embeddings</a>
    3. <a href="https://www.analyticsvidhya.com/blog/2021/06/part-7-step-by-step-guide-to-master-nlp-word-embedding/
">part-7-step-by-step-guide-to-master-nlp-word-embedding</a>
18. topic modelling LDA
    1. <a href="https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/
">topic-modeling-gensim-python</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2021/07/topic-modelling-with-lda-a-hands-on-introduction/
">topic-modelling-with-lda-a-hands-on-introduction</a>
    3. <a href="https://www.analyticsvidhya.com/blog/2021/05/topic-modelling-in-natural-language-processing/
">topic-modelling-in-natural-language-processing</a>
19. topic modelling LSA
    1. <a href="https://www.analyticsvidhya.com/blog/2021/06/part-16-step-by-step-guide-to-master-nlp-topic-modelling-using-lsa/
">part-16-step-by-step-guide-to-master-nlp-topic-modelling-using-lsa</a>
20. https towardsdatascience com 2 latent methods for dimension reduction and topic modeling 20ff6d7d547 text Both 20LSA 20and 20LDA 20have LDA 20solves 20topic 20modeling 20problems text It 20is 20critical 20part 20when 20you 20use 20LSA 2C 20LSI 20and 20LDA
21. Topic model evaluation
22. https towardsdatascience com evaluate topic model in python latent dirichlet allocation lda 7d57484bb5d0 text Topic 20Coherence 20measures 20score 20a are 20artifacts 20of 20statistical 20inference
    1. <a href="https://highdemandskills.com/topic-model-evaluation/
">topic-model-evaluation</a>
23. drawbacks of LSTM
    1. <a href="https://www.geeksforgeeks.org/understanding-of-lstm-networks/
">understanding-of-lstm-networks</a>
24. BERT
    1. <a href="https://www.thepythoncode.com/article/pretraining-bert-huggingface-transformers-in-python
">pretraining-bert-huggingface-transformers-in-python</a>
    2. <a href="https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/
">a-visual-guide-to-using-bert-for-the-first-time</a>
25. BERT pre training and from scratch
    1. <a href="https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python
">finetuning-bert-using-huggingface-transformers-python</a>
    2. <a href="https://www.thepythoncode.com/article/pretraining-bert-huggingface-transformers-in-python
">pretraining-bert-huggingface-transformers-in-python</a>
26. Best link to understand attention BERT and transformer
    1. <a href="https://towardsdatascience.com/breaking-bert-down-430461f60efb
">breaking-bert-down-430461f60efb</a>
27. BERT limitations
    1. <a href="https://medium.com/dair-ai/bert-is-extremely-inefficient-this-is-how-to-solve-it-688b09350f10
">bert-is-extremely-inefficient-this-is-how-to-solve-it-688b09350f10</a>
28. DS case study
    1. <a href="https://workera.ai/resources/data-science-case-study-interview
">data-science-case-study-interview</a>
    2. <a href="https://eng.lyft.com/lyft-marketing-automation-b43b7b7537cc   -Marketting automation 
">LINK</a>
29. Logistic Regression
    1. <a href="https://www.analyticsvidhya.com/blog/2021/07/an-introduction-to-logistic-regression/
">an-introduction-to-logistic-regression</a>
    2. <a href="https://towardsai.net/p/machine-learning/logistic-regression-with-mathematics
">logistic-regression-with-mathematics</a>
30. why can not use linear regression for classification problems
    1. <a href="https://www.analyticsvidhya.com/blog/2020/10/demystification-of-logistic-regression/
">demystification-of-logistic-regression</a>
31. Linear Regression
    1. <a href="https://www.analyticsvidhya.com/blog/2021/10/everything-you-need-to-know-about-linear-regression/
">everything-you-need-to-know-about-linear-regression</a>
    2. <a href="https://towardsdatascience.com/linear-regression-modeling-and-assumptions-dcd7a201502a
">linear-regression-modeling-and-assumptions-dcd7a201502a</a>
32. improve your regression model using 5 tips that no one talks about
    1. <a href="https://medium.datadriveninvestor.com/improve-your-regression-model-using-5-tips-that-no-one-talks-about-a0f21eaeb595
">improve-your-regression-model-using-5-tips-that-no-one-talks-about-a0f21eaeb595</a>
33. MSE or R Squared which one to use
    1. <a href="https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/
">mean-square-error-r-squared-which-one-to-use</a>
34. VIF
    1. <a href="https://www.analyticsvidhya.com/blog/2020/03/what-is-multicollinearity/
">what-is-multicollinearity</a>
    2. <a href="https://towardsdatascience.com/linear-regression-modeling-and-assumptions-dcd7a201502a
">linear-regression-modeling-and-assumptions-dcd7a201502a</a>
35. Non constant error variance heteroscedasticity
    1. <a href="https://statisticsbyjim.com/regression/heteroscedasticity-regression/
">heteroscedasticity-regression</a>
    2. <a href="https://www.statology.org/constant-variance-assumption/
">constant-variance-assumption</a>
36. when to use RMSE and MAE for loss function
    1. <a href="https://medium.com/analytics-vidhya/mae-mse-rmse-coefficient-of-determination-adjusted-r-squared-which-metric-is-better-cd0326a5697e
">mae-mse-rmse-coefficient-of-determination-adjusted-r-squared-which-metric-is-better-cd0326a5697e</a>
37. feature engineering
    1. <a href="https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114
">feature-engineering-for-machine-learning-3a5e293a5114</a>
38. when to use normalisation and standardisation
    1. <a href="https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff
">how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff</a>
39. Data Imbalance
    1. <a href="https://neptune.ai/blog/how-to-deal-with-imbalanced-classification-and-regression-data
">how-to-deal-with-imbalanced-classification-and-regression-data</a>
    2. <a href="https://analyticsindiamag.com/5-important-techniques-to-process-imbalanced-data-in-machine-learning/
">5-important-techniques-to-process-imbalanced-data-in-machine-learning</a>
    3. <a href="https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/
">10-techniques-to-deal-with-class-imbalance-in-machine-learning</a>
40. ROC curve and Precision recall curve when to use when
    1. <a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/
">roc-curves-and-precision-recall-curves-for-classification-in-python</a>
41. RandomisedsearchCV and GridSearchCV for hyperparameter tuning
    1. <a href="https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/
">hyperparameter-optimization-with-random-search-and-grid-search</a>
42. PCA
    1. <a href="https://www.analyticsvidhya.com/blog/2021/09/pca-and-its-underlying-mathematical-principles/
">pca-and-its-underlying-mathematical-principles</a>
43. https medium com analytics vidhya pca vs t sne 17bcd882bf3d text t 2DSNE 20is 20also 20a large 20pairwise 20distance 20maximize 20variance text It 20takes 20a 20set 20of it 20into 20low 20dimensional 20data
    1. <a href="https://www.analyticsvidhya.com/blog/2017/01/t-sne-implementation-r-python/
">t-sne-implementation-r-python</a>
44. PCA and TSNA difference
    1. <a href="https://www.geeksforgeeks.org/difference-between-pca-vs-t-sne/
">difference-between-pca-vs-t-sne</a>
45. Categorial Encoding techniques and hashing encoding techniques
    1. <a href="https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/
">types-of-categorical-data-encoding</a>
46. CrossValidation and Nested Cross validation
    1. <a href="https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79
">5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79</a>
    2. <a href="https://learn.g2.com/cross-validation
">cross-validation</a>
    3. <a href="https://www.analyticsvidhya.com/blog/2021/05/4-ways-to-evaluate-your-machine-learning-model-cross-validation-techniques-with-python-code/
">4-ways-to-evaluate-your-machine-learning-model-cross-validation-techniques-with-python-code</a>
    4. <a href="https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/
">a-step-by-step-guide-to-nested-cross-validation</a>
    5. <a href="https://vitalflux.com/python-nested-cross-validation-algorithm-selection/
">python-nested-cross-validation-algorithm-selection</a>
47. https mlfromscratch com nested cross validation python code
48. model Explanability LIME
    1. <a href="https://www.analyticsvidhya.com/blog/2019/08/decoding-black-box-step-by-step-guide-interpretable-machine-learning-models-python/
">decoding-black-box-step-by-step-guide-interpretable-machine-learning-models-python</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2017/06/building-trust-in-machine-learning-models/
">building-trust-in-machine-learning-models</a>
49. TimeSeries forcasting
    1. <a href="https://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/
">time-series-forecasting-methods</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-to-time-series-analysis/
">a-comprehensive-guide-to-time-series-analysis</a>
    3. <a href="https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/
">arima-model-time-series-forecasting-python</a>
    4. <a href="https://towardsdatascience.com/time-series-forecasting-arima-models-7f221e9eee06
">time-series-forecasting-arima-models-7f221e9eee06</a>
    5. <a href="https://www.analyticsvidhya.com/blog/2021/07/abc-of-time-series-forecasting/
">abc-of-time-series-forecasting</a>
50. SARIMA
    1. <a href="https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/
">sarima-for-time-series-forecasting-in-python</a>
51. gridsearch ARIMA
    1. <a href="https://machinelearningmastery.com/grid-search-arima-hyperparameters-with-python/
">grid-search-arima-hyperparameters-with-python</a>
52. auto arima
    1. <a href="https://towardsdatascience.com/time-series-forecasting-using-auto-arima-in-python-bb83e49210cd
">time-series-forecasting-using-auto-arima-in-python-bb83e49210cd</a>
53. propphet
    1. <a href="https://machinelearningmastery.com/time-series-forecasting-with-prophet-in-python/
">time-series-forecasting-with-prophet-in-python</a>
54. COURSERA Model Deployment Courses
    1. <a href="https://www.coursera.org/learn/deploying-machine-learning-models-in-production/home/week/1
">1</a>
    2. <a href="https://www.coursera.org/learn/introduction-to-machine-learning-in-production/home/welcome
">home/welcome</a>
55. Data and concept Drift
    1. <a href="https://towardsdatascience.com/machine-learning-in-production-why-you-should-care-about-data-and-concept-drift-d96d0bc907fb
">machine-learning-in-production-why-you-should-care-about-data-and-concept-drift-d96d0bc907fb</a>
    2. <a href="https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/
">how-to-monitor-machine-learning-models</a>
56. PySpark parallelization of bigdata
57. https sparkbyexamples com pyspark tutorial features
    1. <a href="https://learning.oreilly.com/videos/spark-ray-and/9780136805922/
">9780136805922</a>
58. deciding number of partitions in spark
    1. <a href="https://www.projectpro.io/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297
">297</a>
59. SMOTE
    1. <a href="https://analyticsindiamag.com/how-can-smote-technique-improve-the-performance-of-weak-learners/
">how-can-smote-technique-improve-the-performance-of-weak-learners</a>
60. Pyspark
    1. <a href="https://sparkbyexamples.com/pyspark-tutorial/.  - best for pyspark inbuilt api's
">LINK</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2019/11/build-machine-learning-pipelines-pyspark/
">build-machine-learning-pipelines-pyspark</a>
    3. <a href="https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/
">comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark</a>
    4. <a href="https://thenewstack.io/the-good-bad-and-ugly-apache-spark-for-data-science-work/
">the-good-bad-and-ugly-apache-spark-for-data-science-work</a>
    5. <a href="https://towardsdatascience.com/strategies-of-spark-join-c0e7b4572bcf
">strategies-of-spark-join-c0e7b4572bcf</a>
    6. <a href="https://medium.com/swlh/pyspark-eda-basics-practical-parallel-processing-f852a151c930
">pyspark-eda-basics-practical-parallel-processing-f852a151c930</a>
61. Creating a Spark job using Pyspark and executing it in AWS EMR
    1. <a href="https://kulasangar.medium.com/creating-a-spark-job-using-pyspark-and-executing-it-in-aws-emr-70dba5e98a75 
">LINK</a>
62. Train an ML Model using Apache Spark in EMR and deploy in SageMaker
    1. <a href="https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-python-sdk/sparkml_serving_emr_mleap_abalone/sparkml_serving_emr_mleap_abalone.html
">sparkml_serving_emr_mleap_abalone</a>
63. scale big ML applications
    1. <a href="https://neptune.ai/blog/how-to-scale-ml-projects
">how-to-scale-ml-projects</a>
    2. <a href="https://www.codementor.io/blog/scalable-ml-models-6rvtbf8dsd
">scalable-ml-models-6rvtbf8dsd</a>
    3. <a href="https://towardsdatascience.com/machine-learning-with-big-data-86bcb39f2f0b
">machine-learning-with-big-data-86bcb39f2f0b</a>
64. ML Pipelines in AWS coursera featurestore model train debug deploy automate everything
    1. <a href="https://www.coursera.org/learn/ml-pipelines-bert
">ml-pipelines-bert</a>
65. ML design architect questions
    1. <a href="https://towardsdatascience.com/architecting-a-machine-learning-pipeline-a847f094d1c7
">architecting-a-machine-learning-pipeline-a847f094d1c7</a>
    2. <a href="https://towardsdatascience.com/what-is-machine-learning-system-design-interview-and-how-to-prepare-for-it-537d1271d754
">what-is-machine-learning-system-design-interview-and-how-to-prepare-for-it-537d1271d754</a>
    3. <a href="https://towardsdatascience.com/how-to-answer-any-machine-learning-system-design-interview-question-a98656bb7ff0       - good one
">LINK</a>
    4. <a href="https://vitalflux.com/data-science-architect-interview-questions/.  - good one
">LINK</a>
66. how to monitor your models in production guide Population stability Index PSI
    1. <a href="https://neptune.ai/blog/how-to-monitor-your-models-in-production-guide
">how-to-monitor-your-models-in-production-guide</a>
    2. <a href="https://towardsdatascience.com/psi-and-csi-top-2-model-monitoring-metrics-924a2540bed8
">psi-and-csi-top-2-model-monitoring-metrics-924a2540bed8</a>
    3. <a href="https://towardsdatascience.com/using-statistical-distance-metrics-for-machine-learning-observability-4c874cded78
">using-statistical-distance-metrics-for-machine-learning-observability-4c874cded78</a>
67. MLOPS In AWS
68. Ml Ops Sagemaker Studio
    1. <a href="https://www.youtube.com/watch?v=iNoeULI7nB4
">LINK</a>
69. Model Deployment using AWS Lambda and REST API s
    1. <a href="https://towardsdatascience.com/a-practical-guide-to-mlops-in-aws-sagemaker-part-i-1d28003f565
">a-practical-guide-to-mlops-in-aws-sagemaker-part-i-1d28003f565</a>
    2. <a href="https://towardsdatascience.com/a-practical-guide-to-mlops-using-aws-sagemaker-part-ii-c5159b4b51aa
">a-practical-guide-to-mlops-using-aws-sagemaker-part-ii-c5159b4b51aa</a>
    3. <a href="https://medium.com/@pradeep.natarajan2012/mlops-with-amazon-web-services-754758ecc1df
">mlops-with-amazon-web-services-754758ecc1df</a>
70. AWS Sagemkaer Documentation
    1. <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/deployment-guardrails.html
">deployment-guardrails</a>
71. Sagemaker inference cost optimization
    1. <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/inference-cost-optimization.html
">inference-cost-optimization</a>
72. Feature Store Online ofline
    1. <a href="https://towardsdatascience.com/do-you-really-need-a-feature-store-e59e3cc666d3
">do-you-really-need-a-feature-store-e59e3cc666d3</a>
    2. <a href="https://towardsdatascience.com/real-time-feature-engineering-with-a-feature-store-2d51ce925734
">real-time-feature-engineering-with-a-feature-store-2d51ce925734</a>
73. ML Model Testing Writing Unit and Integration test cases
    1. <a href="https://neptune.ai/blog/automated-testing-machine-learning - BEST
">LINK</a>
    2. <a href="https://towardsdatascience.com/checklist-behavioral-testing-of-nlp-models-491cf11f0238 Good
">LINK</a>
    3. <a href="https://madewithml.com/courses/mlops/testing/.  - BEST 
">LINK</a>
    4. <a href="https://deepchecks.com/how-to-test-machine-learning-models/
">how-to-test-machine-learning-models</a>
    5. <a href="https://deepchecks.com/machine-learning-testing-principles-making-sure-your-model-does-what-you-think-it-should-do/
">machine-learning-testing-principles-making-sure-your-model-does-what-you-think-it-should-do</a>
    6. <a href="https://www.jeremyjordan.me/testing-ml/
">testing-ml</a>
    7. <a href="https://www.analyticsvidhya.com/blog/2022/01/writing-test-cases-for-machine-learning/
">writing-test-cases-for-machine-learning</a>
    8. <a href="https://towardsdatascience.com/unit-testing-in-deep-learning-b91d366e4862
">unit-testing-in-deep-learning-b91d366e4862</a>
    9. <a href="https://medium.com/pykes-technical-notes/testing-machine-learning-systems-unit-tests-38696264ee04
">testing-machine-learning-systems-unit-tests-38696264ee04</a>
    10. <a href="https://www.xenonstack.com/blog/machine-learning-unit-testing
">machine-learning-unit-testing</a>
74. Regularization
    1. <a href="https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/
">fundamentals-deep-learning-regularization-techniques</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/
">a-comprehensive-guide-for-linear-ridge-and-lasso-regression</a>
    3. <a href="https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/
">ridge-lasso-regression-python-complete-tutorial</a>
75. Bias Variance
    1. <a href="https://www.javatpoint.com/bias-and-variance-in-machine-learning
">bias-and-variance-in-machine-learning</a>
76. designing A B testing
    1. <a href="https://aws.amazon.com/blogs/machine-learning/a-b-testing-ml-models-in-production-using-amazon-sagemaker/
">a-b-testing-ml-models-in-production-using-amazon-sagemaker</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2020/10/ab-testing-data-science/
">ab-testing-data-science</a>
77. Business Case studies Interview questions
    1. <a href="https://towardsdatascience.com/the-ultimate-guide-to-cracking-business-case-interviews-for-data-scientists-part-1-cb768c37edf4
">the-ultimate-guide-to-cracking-business-case-interviews-for-data-scientists-part-1-cb768c37edf4</a>
    2. <a href="https://www.interviewquery.com/p/data-science-case-study-interview-questions
">data-science-case-study-interview-questions</a>
    3. <a href="https://www.projectpro.io/article/data-science-case-study-interview-questions-and-answers/557
">557</a>
    4. <a href="https://medium.com/datainterview/crack-the-data-scientist-case-interview-by-an-ex-google-data-scientist-f44da750cffe
">crack-the-data-scientist-case-interview-by-an-ex-google-data-scientist-f44da750cffe</a>
    5. <a href="https://www.tredence.com/case-studies/rebate-analytics-solution
">rebate-analytics-solution</a>
    6. <a href="https://www.tredence.com/case-studies/developed-a-scalable-web-based-rebate-analytics-solution
">developed-a-scalable-web-based-rebate-analytics-solution</a>
78. https www tredence com products healthem ai contact
    1. <a href="https://www.tredence.com/assets/case-studies/developing_a_customer_data_platform.pdf
">developing_a_customer_data_platform</a>
    2. <a href="https://www.tredence.com/assets/case-studies/improving_demand_forecast_accuracy.pdf
">improving_demand_forecast_accuracy</a>
79. AWS Services
    1. <a href="https://towardsdatascience.com/5-aws-services-every-data-scientist-should-use-1fdbf9a784d2
">5-aws-services-every-data-scientist-should-use-1fdbf9a784d2</a>
80. 1 AWS EMR
    1. <a href="https://www.youtube.com/watch?v=qLnamoLaIzU
">LINK</a>
81. AWS Glue
    1. <a href="2.)https://www.youtube.com/watch?v=Qpv7BzOM-UI
">LINK</a>
82. AWS step functions
    1. <a href="https://www.youtube.com/watch?v=zCIpWFYDJ8s
">LINK</a>
    2. <a href="https://www.youtube.com/watch?v=s0XFX3WHg0w
">LINK</a>
83. Amazon quickSight
    1. <a href="https://www.youtube.com/watch?v=WaOrQtxLXfs
">LINK</a>
84. designing machine learning
85. https learning oreilly com library view designing machine learning 9781098107956 ch05 html discretization
86. Discretization
87. https learning oreilly com library view designing machine learning 9781098107956 ch05 html discretization
88. Feature geenralization
89. https learning oreilly com library view designing machine learning 9781098107956 ch05 html feature_generalization
90. data normalization before or after train test split
    1. <a href="https://datascience.stackexchange.com/questions/54908/data-normalization-before-or-after-train-test-split
">data-normalization-before-or-after-train-test-split</a>
91. Data Leakage
    1. <a href="https://rakesh4423.medium.com/how-to-prevent-data-leakage-406fd77ecd0d
">how-to-prevent-data-leakage-406fd77ecd0d</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/
">data-leakage-and-its-effect-on-the-performance-of-an-ml-model</a>
    3. <a href="https://towardsdatascience.com/preventing-data-leakage-in-your-machine-learning-model-9ae54b3cd1fb
">preventing-data-leakage-in-your-machine-learning-model-9ae54b3cd1fb</a>
92. Things to Cover
    1. <a href="https://www.linkedin.com/in/saurabh-kumar-0407863/details/experience/
">experience</a>
    2. <a href="https://www.linkedin.com/in/aishwarya-chowdhary-983a25a1/
">aishwarya-chowdhary-983a25a1</a>
    3. <a href="https://www.linkedin.com/in/sahil-gupta-78745084/
">sahil-gupta-78745084</a>
    4. <a href="https://www.linkedin.com/in/praveen-sharma-89b61a1b/
">praveen-sharma-89b61a1b</a>
93. ML DS Interview questions
    1. <a href="https://www.linkedin.com/posts/activity-6952040254644113408-97DZ/?utm_source=linkedin_share&utm_medium=member_desktop_web
">LINK</a>
94. statistics and Probablity
    1. <a href="https://datasciencestunt.com/standard-deviation-and-variance-in-statistics/
">standard-deviation-and-variance-in-statistics</a>
    2. <a href="https://keydifferences.com/difference-between-variance-and-standard-deviation.html
">difference-between-variance-and-standard-deviation</a>
95. Hypothesis testing and P value
    1. <a href="https://www.analyticsvidhya.com/blog/2021/09/hypothesis-testing-in-machine-learning-everything-you-need-to-know/
">hypothesis-testing-in-machine-learning-everything-you-need-to-know</a>
    2. <a href="https://www.analyticsvidhya.com/blog/2020/07/hypothesis-testing-68351/
">hypothesis-testing-68351</a>
96. covariance and correlation difference
    1. <a href="https://careerfoundry.com/en/blog/data-analytics/covariance-vs-correlation/
">covariance-vs-correlation</a>
97. https www simplilearn com covariance vs correlation article text Covariance 20and 20correlation 20are 20two the 20two 20variables 20are 20related
98. geenral statistics links
    1. <a href="https://towardsdatascience.com/probability-and-statistics-for-data-science-part-1-3eed6051c40d
">probability-and-statistics-for-data-science-part-1-3eed6051c40d</a>
    2. <a href="https://medium.com/technology-nineleaps/basics-of-statistics-for-machine-learning-engineers-ii-d25c5a5dac67
">basics-of-statistics-for-machine-learning-engineers-ii-d25c5a5dac67</a>
99. distance measures in ML
    1. <a href="https://vitalflux.com/different-types-of-distance-measures-in-machine-learning/
">different-types-of-distance-measures-in-machine-learning</a>
    2. <a href="https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7
">different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7</a>
    3. <a href="https://towardsdatascience.com/how-to-decide-the-perfect-distance-metric-for-your-machine-learning-model-2fa6e5810f11
">how-to-decide-the-perfect-distance-metric-for-your-machine-learning-model-2fa6e5810f11</a>
100. Naive Bayes and Conditional probablity
    1. <a href="https://www.analyticsvidhya.com/blog/2021/09/naive-bayes-algorithm-a-complete-guide-for-data-science-enthusiasts/
">naive-bayes-algorithm-a-complete-guide-for-data-science-enthusiasts</a>
    2. <a href="https://blog.floydhub.com/naive-bayes-for-machine-learning/
">naive-bayes-for-machine-learning</a>
    3. <a href="https://medium.com/mlearning-ai/probability-the-bedrock-of-machine-learning-algorithms-a1af0388ea75
">probability-the-bedrock-of-machine-learning-algorithms-a1af0388ea75</a>
101. naive Bayespractical explanation
    1. <a href="https://www.kdnuggets.com/2019/10/bayes-theorem-applied-machine-learning.html
">bayes-theorem-applied-machine-learning</a>
102. 6 Common Probability Distributions
    1. <a href="https://www.analyticsvidhya.com/blog/2017/09/6-probability-distributions-data-science/
">6-probability-distributions-data-science</a>
    2. <a href="https://vitalflux.com/types-probability-distributions-defined-examples/
">types-probability-distributions-defined-examples</a>
    3. <a href="https://machinelearningknowle
">/machinelearningknowle</a>
103. Cdntral limit theoram
    1. <a href="https://www.analyticsvidhya.com/blog/2019/05/statistics-101-introduction-central-limit-theorem/
">statistics-101-introduction-central-limit-theorem</a>
104. 3 Udemy course A rigorous and engaging deep dive into statistics and machine learning with hands on applications in Python and MATLAB
105. FAAANG Interview Links
106. sql
    1. <a href="https://datalemur.com/questions
">datalemur</a>
107. general interview
    1. <a href="https://towardsdatascience.com/30-data-science-interview-questions-from-faang-tech-giants-1eea134db7c7
">30-data-science-interview-questions-from-faang-tech-giants-1eea134db7c7</a>
    2. <a href="https://faangpath.com/blog/amazon-data-scientist-interview/
">amazon-data-scientist-interview</a>
 
KEY POINTS
1. As a rule of thumb, you should always use the equality operators == and !=, except when you’re comparing to None:
2. •	Use the Python == and != operators to compare object equality. Here, you’re generally comparing the value of two objects. This is what you need if you want to compare whether or not two objects have the same contents, and you don’t care about where they’re stored in memory.
3. •	Use the Python is and is not operators when you want to compare object identity. Here, you’re comparing whether or not two variables point to the same object in memory. The main use case for these operators is when you’re comparing to None. It’s faster and safer to compare to None by memory address than it is by using class methods.
4. Variables with the same value are often stored at separate memory addresses. This means that you should use == and != to compare their values and use the Python is and is not operators only when you want to check whether two variables point to the same memory address.
5. http://vision.is.tohoku.ac.jp/~kyamagu/papers/yashima2016learning.pdf
6. analyticsvidhya.com/blog/2021/09/guide-for-building-an-end-to-end-logistic-regression-model/
7. Multicollinearity can be detected using the Variance Inflation Factor (VIF). VIF of any predictor is the ratio of variance of its estimated coefficient in the full model to the variance of its estimated coefficient when fit on the outcome only by itself (as in simple linear regression).
8. Compare ARIMA and LSTM
9. LSTM works better if we are dealing with huge amount of data and enough training data is available, while ARIMA is better for smaller datasets (is this correct?)
10. ARIMA requires a series of parameters (p,q,d) which must be calculated based on data, while LSTM does not require setting such parameters. However, there are some hyperparameters we need to tune for LSTM.
11. EDIT: One major difference between the two that I noticed while reading a great article here, is that ARIMA could only perform well on stationary time series (where there is no seasonality, trend and etc.) and you need to take care of that if want to use ARIMA
12. Cloud Read
13. Augmented AI,AWS Athena,AWS lambda Services > trigger Pagemaker instance>
14. As soon new files comes in S3, was lambda triggered and trigger pagemaker instance
15. As new records in S3 bucket are placed then AWS triggers and initiates model retraining
16. training-serving skew
17. Training-serving skew is a difference between performance during training and performance during serving. This skew can be caused by: A discrepancy between how you handle data in the training and serving pipelines. A change in the data between when you train and when you serve.18-Jul-2022
18. http://patrickhalina.com/posts/ml-systems-design-interview-guide/
19. Blue/Green: All At Once shifts all of your endpoint traffic from the blue fleet to the green fleet. Once the traffic shifts to the green fleet, your pre-specified Amazon CloudWatch alarms begin monitoring the green fleet for a set amount of time (the baking period). If no alarms trip during the baking period, then SageMaker terminates the blue fleet.
20. Blue/Green: Canary lets you shift one small portion of your traffic (a canary) to the green fleet and monitor it for a baking period. If the canary succeeds on the green fleet, then SageMaker shifts the rest of the traffic from the blue fleet to the green fleet before terminating the blue fleet.
21. Blue/Green: Linear provides even more customization over the number of traffic-shifting steps and the percentage of traffic to shift for each step. While canary shifting lets you shift traffic in two steps, linear shifting extends this to n linearly spaced steps.
22. why ensembling  improves
23. We’ll go over an example to give you the intuition of why ensembling works. Imagine you have three email spam classifiers, each with an accuracy of 70%. Assuming that each classifier has an equal probability of making a correct prediction for each email, and that these three classifiers are not correlated, we’ll show that by taking the majority vote of these three classifiers, we can get an accuracy of 78.4%.
24. For each email, each classifier has a 70% chance of being correct. The ensemble will be correct if at least two classifiers are correct. Table 6-1 shows the probabilities of different possible outcomes of the ensemble given an email. This ensemble will have an accuracy of 0.343 + 0.441 = 0.784, or 78.4%.
25. Table 6-1. Possible outcomes of the ensemble that takes the majority vote from three classifiers
26. Outputs of three models	Probability	Ensemble’s output
27. All three are correct	0.7 * 0.7 * 0.7 = 0.343	Correct
28. Only two are correct	(0.7 * 0.7 * 0.3) * 3 = 0.441	Correct
29. Only one is correct	(0.3 * 0.3 * 0.7) * 3 = 0.189	Wrong
30. None are correct	0.3 * 0.3 * 0.3 = 0.027	Wrong
31. This calculation only holds if the classifiers in an ensemble are uncorrelated. If all classifiers are perfectly correlated—all three of them make the same prediction for every email—the ensemble will have the same accuracy as each individual classifier. When creating an ensemble, the less correlation there is among base learners, the better the ensemble will be. Therefore, it’s common to choose very different types of models for an ensemble. For example, you might create an ensemble that consists of one transformer model, one recurrent neural network, and one gradient-boosted tree.
32. Discretization
33. This technique is included in this book for completeness, though in practice, I’ve rarely found discretization to help. Imagine that we’ve built a model with the data in Table 5-2. During training, our model has seen the annual income values of “150,000,” “50,000,” “100,000,” and so on. During inference, our model encounters an example with an annual income of “9,000.50.”
34. Intuitively, we know that $9,000.50 a year isn’t much different from $10,000/year, and we want our model to treat both of them the same way. But the model doesn’t know that. Our model only knows that 9,000.50 is different from 10,000, and it will treat them differently.
35. Discretization is the process of turning a continuous feature into a discrete feature. This process is also known as quantization or binning. This is done by creating buckets for the given values. For annual income, you might want to group them into three buckets as follows:
36. Lower income: less than $35,000/year
37. Middle income: between $35,000 and $100,000/year
38. Upper income: more than $100,000/year
39. Instead of having to learn an infinite number of possible incomes, our model can focus on learning only three categories, which is a much easier task to learn. This technique is supposed to be more helpful with limited training data.
40. Even though, by definition, discretization is meant for continuous features, it can be used for discrete features too. The age variable is discrete, but it might still be useful to group the values into buckets such as follows:
41. Less than 18
42. Between 18 and 22
43. Between 22 and 30
44. Between 30 and 40
45. Between 40 and 65
46. Over 65
47. The downside is that this categorization introduces discontinuities at the category boundaries—$34,999 is now treated as completely different from $35,000, which is treated the same as $100,000. Choosing the boundaries of categories might not be all that easy. You can try to plot the histograms of the values and choose the boundaries that make sense. In general, common sense, basic quantiles, and sometimes subject matter expertise can help.
48. DISADVANTAGES OF ADDING MORE FEATURES IN MODEL
49. Generally, adding more features leads to better model performance. In my experience, the list of features used for a model in production only grows over time. However, more features doesn’t always mean better model performance. Having too many features can be bad both during training and serving your model for the following reasons:
50. The more features you have, the more opportunities there are for data leakage.
51. Too many features can cause overfitting.
52. Too many features can increase memory required to serve a model, which, in turn, might require you to use a more expensive machine/instance to serve your model.
53. Too many features can increase inference latency when doing online prediction, especially if you need to extract these features from raw data for predictions online. We’ll go deeper into online prediction in Chapter 7.
54. Useless features become technical debts. Whenever your data pipeline changes, all the affected features need to be adjusted accordingly. For example, if one day your application decides to no longer take in information about users’ age, all features that use users’ age need to be updated.
55. Feature Generalization : This rule of thumb is rough because some features can still be useful even if they are missing in most of your data. This is especially true when the missing values are not at random, which means having the feature or not might be a strong indication of its value. For example, if a feature appears only in 1% of your data, but 99% of the examples with this feature have POSITIVE labels, this feature is useful and you should use it.
56. Here is a summary of best practices for feature engineering
57. Split data by time into train/valid/test splits instead of doing it randomly.
58. If you oversample your data, do it after splitting.
59. Scale and normalize your data after splitting to avoid data leakage.
60. Use statistics from only the train split, instead of the entire data, to scale your features and handle missing values.
61. Understand how your data is generated, collected, and processed. Involve domain experts if possible.
62. Keep track of your data’s lineage.
63. Understand feature importance to your model.
64. Use features that generalize well.
65. Remove no longer useful features from your models.
66. Do Normalization after splitting into train and test/validation. The reason is to avoid any data leakage.
67. Data Leakage: Data leakage is when information from outside the training dataset is used to create the model. This additional information can allow the model to learn or know something that it otherwise would not know and in turn invalidate the estimated performance of the mode being constructed.
68. Normalization across instances should be done after splitting the data between training and test set, using only the data from the training set.
69. This is because the test set plays the role of fresh unseen data, so it's not supposed to be accessible at the training stage. Using any information coming from the test set before or during training is a potential bias in the evaluation of the performance.
70. [Precision thanks to Neil's comment] When normalising the test set, one should apply the normalization parameters previously obtained from the training set as-is. Do not recalculate them on the test set, because they would be inconsistent with the model and this would produce wrong predictions.
71. Data leakage happens when Feature Scaling is done before splitting the dataset. Standardizing and Normalizing are done by finding the mean, variance, min, max, and standard deviation. So when feature scaling is done before the splitting, we are finding mean and variance for the whole dataset. This is where the leakage happens.
72. Leakage during Data preprocessing
73. While solving a Machine learning problem statement, firstly we do the data cleaning and preprocessing which involves the following steps:
74. Evaluating the parameters for normalizing or rescaling features
75. Finding the minimum and maximum values of a particular feature
76. Normalize the particular feature in our dataset
77. Removing the outliers
78. Fill or completely remove the missing data in our dataset
79. The above-described steps should be done using only the training set. If we use the entire dataset to perform these operations, data leakage may occur. Applying preprocessing techniques to the entire dataset will cause the model to learn not only the training set but also the test set. As we all know that the test set should be new and previously unseen for any model.
80. 1.) ▪ Building a self-served Machine Learning model Retraining platform which can utilise Batch feeds and inference ML Models using state of the art algorithms like XGBoost, LightGBM etc
81. 2.) ▪ Optimization of workflows to meet the need to scale up the execution of different algorithms on big data.
82. 3.) Making Strategies for credit card limit assignment to different segments to ensure low delinquency rate.
83. Performing acquisition quality monitoring(3M and 6M 30+ bad rate and delinquency) to identify early warning signals and recommend corrective measures.
84. Closely monitoring de-dup applications every month to identify fraud/duplicate applicants.
85. Customer Engagement Score:
86. o The project involved tracking affinity of a customer to our Barclays brand. It drives customers with
87. Consideration, Advocacy and Loyalty to Barclays.
88. o It is represented as a wheel with a blended score across 4 quadrants i.e. transactional score,
89. relationship score, channel usage score & product holding score.
90. o The scores can be tracked over time. It can be drilled down into its 4 quadrants to understand the
91. score drivers. The distribution of engaged customers by sub-segments can also be monitored
92. Ad-hoc Projects:
93. o Switchers and New to Bank deep dive analysis: The objective of this analysis was to understand if
94. switch in customers are more valuable to the bank. The analysis focused on comparing new to bank
95. customers through switch in and direct new to bank customers. This was done to inform the design
96. of switcher offer incentive and customer acquisition strategy.
97. o Focus Drivers Analysis: Built Decision Tree model to understand the key drivers supporting customers
98. upgrade to focus or retain in focus and their influence on customers’ likelihood to become focus
99. within a defined period of time. This was done for targeting purpose.
100. o Premier Commercial Segmentation: Developed Commercial segmentation base on off-us
101. opportunity, on-usvalue and engagement score with objective of enabling more targeted approach
102. through contact.
103. Other Initiatives at work:
104. o Successfully delivered trainings on ‘Introduction to Machine learning’ and ‘EDA’ along with
105. banking applications to the entire team in Noida as well as UK counterparts.
106. o Apart from my projects, I have managed to prepare a tool on excel which enables new joiners or for any
107. team member to understand key definitions, important concepts, commonly used codes and datasets
108. 1. Fraud detection and blocking fraudulent merchants proactively
109. 2. Segmentation of customers who are visiting to branch into 2 cohorts: those who CAN/CAN’T
110. switch to digital channels
111. 3. Process Optimization of Direct Debit Cancellation at the time of customer’s bereavement
112. 4. Debit Card Controls Analysis to understand whether controls provided to customers for
113. secure online transaction are effective and secure
114. 5. Debit Cards Portfolio analysis to understand bank’s readiness for seamless customer’s
115. contactless journey
116. NLP things to cover
117. Creating knowledge graph> Json parsed file> Policy PDF documents
118. Intent classification>NER>knowledge graph query formation (graph query engine)
119. Marketing Mix Optimization, Price Optimization,Propensity Modeling,
120. PAYTM JD
121. Design and evaluate novel approaches for handling high-volume real-time data streams in a machine learning environment.
122. Develop a feedback system to improve the selection of features for the algorithms.
123. You understand what it takes to deliver ML predictions in real time online applications
124. Having experience in optimization algorithms.
125. difference between standard deviation and variance
126. Standard deviation is the spread of a group of numbers from the mean. The variance measures the average degree to which each point differs from the mean. While standard deviation is the square root of the variance, variance is the average of all data points within a group.
127. measure of centrak tendency(mean,median,mode), probablity and odd ratio,probably mass fucntions and probablity density functions,cumulative dsitribution functions
128. ,Monto Corolo Sampling,Expected value
